- Imported Quick Capture items:
    - “按ChatGPT模式做AI，我们一天成本要3亿”-36氪
        - Annotations:
        - 多位行业人士也承认，若以ChatGPT的能力为标杆对比中国两国在AI领域的差距，中国的AI发展已经滞后，甚至拉开了五年的差距
        - “时间壁垒”带来的则是算法方面的差距。一个基础常识是，算法训练是一件没有办法弯道超车的事情。自2018年，OpenAI推出了第一代生成式预训练模型GPT-1起，OpenAI用了近6年的时间沉淀出了当前的大语言模型。“这六年的差距没办法用半年的时间实现超越，除非有天才少年用更加完善的算法框架实现降维打击。”
        - https://36kr.com/p/2126177181608961 [Email Body](https://files.todoist.com/Flmi2PMSBHyTr6aS4Z0LGAWAXQAjDopsbU028iFV79o6WcKMrwAUs3WQvioBkqaC/by/21878347/as/file.html)
        - Annotations:
        - 多位行业人士也承认，若以ChatGPT的能力为标杆对比中国两国在AI领域的差距，中国的AI发展已经滞后，甚至拉开了五年的差距
        - “时间壁垒”带来的则是算法方面的差距。一个基础常识是，算法训练是一件没有办法弯道超车的事情。自2018年，OpenAI推出了第一代生成式预训练模型GPT-1起，OpenAI用了近6年的时间沉淀出了当前的大语言模型。“这六年的差距没办法用半年的时间实现超越，除非有天才少年用更加完善的算法框架实现降维打击。”
        - https://36kr.com/p/2126177181608961 [Email Body](https://files.todoist.com/Flmi2PMSBHyTr6aS4Z0LGAWAXQAjDopsbU028iFV79o6WcKMrwAUs3WQvioBkqaC/by/21878347/as/file.html)
    - 【国盛计算机】ChatGPT需要多少算力_手机新浪网
        - Annotations:

* 访问算力：初始投入近十亿美元，单日电费数万美元。1）根据Similarweb的数据，2023年1月，平均每天约有1300万独立访客使用ChatGPT。访问阶段算力每天发生，其成本成为衡量ChatGPT最主要投入的关键指标。2）我们以英伟达A100芯片、DGX A100服务器、现阶段每日2500万访问量等假设为基础，估算得出：在初始算力投入上，为满足ChatGPT当前千万级用户的咨询量，投入成本约为8亿美元，对应约4000台服务器；在单日运行电费上，参考美国平均0.08美元/kwh工业电价，每日电费约为5万美元，成本相对高昂。

前期训练：公有云下，单次训练约为百万至千万美元。1）模型的前期训练成本也是讨论的重要议题。基于参数数量和token数量估算，GPT-3训练一次的成本约为140万美元；对于一些更大的LLM模型（如拥有2800亿参数的Gopher和拥有5400亿参数的PaLM），采用同样的计算公式，可得出，训练成本介于200万美元至1200万美元之间。2）我们认为，在公有云上，对于全球科技大企业而言，百万至千万美元级别的训练成本并不便宜，但尚在可接受范围内。

*     *       * 英伟达A100：根据OneFlow报道，目前，NVIDIA A100是AWS最具成本效益的GPU选择

* 英伟达DGX A100服务器：单机搭载8片A100 GPU，AI算力性能约为5 PetaFLOP/s，单机最大功率约为6.5kw，售价约为19.9万美元/台。

##

* 标准机柜：19英寸、42U。单个DGX A100服务器尺寸约为6U，则标准机柜可放下约7个DGX A100服务器。则，单个标准机柜的成本为140万美元、56个A100GPU、算力性能为35 PetaFLOP/s、最大功率45.5kw。



https://finance.sina.cn/2023-02-13/detail-imyfpfsz2563335.d.html?from=wap [Email Body](https://files.todoist.com/OZaMzHcA-UoXYWAonoeLOVumwUJD7HaICScuv87DyQ4YLtwMTRCDKhEuM45EkUiD/by/21878347/as/file.html)
        - Annotations:
        - 访问算力：初始投入近十亿美元，单日电费数万美元。1）根据Similarweb的数据，2023年1月，平均每天约有1300万独立访客使用ChatGPT。访问阶段算力每天发生，其成本成为衡量ChatGPT最主要投入的关键指标。2）我们以英伟达A100芯片、DGX A100服务器、现阶段每日2500万访问量等假设为基础，估算得出：在初始算力投入上，为满足ChatGPT当前千万级用户的咨询量，投入成本约为8亿美元，对应约4000台服务器；在单日运行电费上，参考美国平均0.08美元/kwh工业电价，每日电费约为5万美元，成本相对高昂。
        - 前期训练：公有云下，单次训练约为百万至千万美元。1）模型的前期训练成本也是讨论的重要议题。基于参数数量和token数量估算，GPT-3训练一次的成本约为140万美元；对于一些更大的LLM模型（如拥有2800亿参数的Gopher和拥有5400亿参数的PaLM），采用同样的计算公式，可得出，训练成本介于200万美元至1200万美元之间。2）我们认为，在公有云上，对于全球科技大企业而言，百万至千万美元级别的训练成本并不便宜，但尚在可接受范围内。
        - *       * 英伟达A100：根据OneFlow报道，目前，NVIDIA A100是AWS最具成本效益的GPU选择
        - 英伟达DGX A100服务器：单机搭载8片A100 GPU，AI算力性能约为5 PetaFLOP/s，单机最大功率约为6.5kw，售价约为19.9万美元/台。
        - ##
        - 标准机柜：19英寸、42U。单个DGX A100服务器尺寸约为6U，则标准机柜可放下约7个DGX A100服务器。则，单个标准机柜的成本为140万美元、56个A100GPU、算力性能为35 PetaFLOP/s、最大功率45.5kw。
        - https://finance.sina.cn/2023-02-13/detail-imyfpfsz2563335.d.html?from=wap [Email Body](https://files.todoist.com/OZaMzHcA-UoXYWAonoeLOVumwUJD7HaICScuv87DyQ4YLtwMTRCDKhEuM45EkUiD/by/21878347/as/file.html)
    - How David Hume Helped Me Solve My Midlife Crisis - The Atlantic
        - Annotations:

* In my n 我的  own scientific papers I’d argued, like Hume, that the coherent self is an illusion.

* My research had convinced me that our selves are something we construct, not something we discover.



https://archive.ph/fb6yQ [Email Body](https://files.todoist.com/zZMLedMaoq1yUZOjEzVcVIEBlN4dOf6i2ktS-CJC9B2aQ1FZk9dePBTrl-4tQ3bw/by/21878347/as/file.html)
    - ![](https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fxinyiheng%2FJPKC0Dg8mD.png?alt=media&token=0068141f-69be-455f-90a8-9f3dbe75b030)
- ![](https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fxinyiheng%2FpWdv8hEcvp.png?alt=media&token=14804630-7fc0-4e47-99bc-366eb000ed4e)
